{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "\n",
    "# importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# sci-kit learn libraries\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "\n",
    "# set seed\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfs = {}\n",
    "\n",
    "# import training data set\n",
    "train_df = pd.read_csv('../data/train.csv')\n",
    "train_df['_data'] = 'train'\n",
    "dfs['train'] = train_df\n",
    "\n",
    "# import test data set\n",
    "test_df = pd.read_csv('../data/test.csv')\n",
    "test_df['_data'] = 'test'\n",
    "dfs['test'] = test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# combine train and test data\n",
    "combined_df = dfs['train'].append(dfs['test'])\n",
    "\n",
    "# lowercase column names\n",
    "combined_df.columns = map(str.lower, combined_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# parse datetime column & add new time related columns\n",
    "dt = pd.DatetimeIndex(combined_df['datetime'])\n",
    "combined_df.set_index(dt, inplace=True)\n",
    "\n",
    "# create new columns for day, month, year, hour\n",
    "combined_df['date'] = dt.date\n",
    "combined_df['day'] = dt.day\n",
    "combined_df['month'] = dt.month\n",
    "combined_df['year'] = dt.year\n",
    "combined_df['hour'] = dt.hour\n",
    "combined_df['dayofweek'] = dt.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# creating new columns transforming bike ridership to log\n",
    "for column in ['casual', 'registered', 'count']:\n",
    "    combined_df['%s_log' % column] = np.log(combined_df[column] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/IPython/kernel/__main__.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# mark peak hours\n",
    "#combined_df['peak'] = combined_df[['hour', 'workingday']].apply(lambda x: (0, 1)[(x['workingday'] == 1 and  ( x['hour'] == 8 or 17 <= x['hour'] <= 18 or 12 <= x['hour'] <= 12)) or (x['workingday'] == 0 and  10 <= x['hour'] <= 19)], axis = 1)\n",
    "\n",
    "# mark peak hours\n",
    "# sat/sun - 10am to 7pm\n",
    "# mon-fri - 6am to 10am | 4pm to 7pm\n",
    "combined_df['peak'] = 0\n",
    "combined_df['peak'][(\n",
    "        ( (combined_df['workingday'] == 0 ) & ( (combined_df['hour'] >= 10) & (combined_df['hour'] <= 19) ) ) |\n",
    "        ( \n",
    "            (combined_df['workingday'] == 1 ) & \n",
    "            ( \n",
    "               ( (combined_df['hour'] >= 6) & (combined_df['hour'] <= 10) ) | \n",
    "               ( (combined_df['hour'] >= 16) & (combined_df['hour'] <= 19) )\n",
    "            )\n",
    "        )\n",
    "    )] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# defined perfect weather and humid weather variables\n",
    "combined_df['perfect'] = combined_df[['temp', 'windspeed']].apply(lambda x: (0, 1)[x['temp'] > 27 and x['windspeed'] < 30], axis = 1)\n",
    "combined_df['humid'] = combined_df[['humidity', 'workingday']].apply(lambda x: (0, 1)[x['workingday'] == 1 and x['humidity'] >= 60], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_data</th>\n",
       "      <th>atemp</th>\n",
       "      <th>casual</th>\n",
       "      <th>count</th>\n",
       "      <th>datetime</th>\n",
       "      <th>holiday</th>\n",
       "      <th>humidity</th>\n",
       "      <th>registered</th>\n",
       "      <th>season</th>\n",
       "      <th>temp</th>\n",
       "      <th>...</th>\n",
       "      <th>year</th>\n",
       "      <th>hour</th>\n",
       "      <th>dow</th>\n",
       "      <th>casual_log</th>\n",
       "      <th>registered_log</th>\n",
       "      <th>count_log</th>\n",
       "      <th>peak</th>\n",
       "      <th>perfect</th>\n",
       "      <th>humid</th>\n",
       "      <th>dayofweek</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011-01-01 00:00:00</th>\n",
       "      <td>train</td>\n",
       "      <td>14.395</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>2011-01-01 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>9.84</td>\n",
       "      <td>...</td>\n",
       "      <td>2011</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>2.639057</td>\n",
       "      <td>2.833213</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 01:00:00</th>\n",
       "      <td>train</td>\n",
       "      <td>13.635</td>\n",
       "      <td>8</td>\n",
       "      <td>40</td>\n",
       "      <td>2011-01-01 01:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>9.02</td>\n",
       "      <td>...</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2.197225</td>\n",
       "      <td>3.496508</td>\n",
       "      <td>3.713572</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 02:00:00</th>\n",
       "      <td>train</td>\n",
       "      <td>13.635</td>\n",
       "      <td>5</td>\n",
       "      <td>32</td>\n",
       "      <td>2011-01-01 02:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>9.02</td>\n",
       "      <td>...</td>\n",
       "      <td>2011</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>3.332205</td>\n",
       "      <td>3.496508</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 03:00:00</th>\n",
       "      <td>train</td>\n",
       "      <td>14.395</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>2011-01-01 03:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>9.84</td>\n",
       "      <td>...</td>\n",
       "      <td>2011</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>2.397895</td>\n",
       "      <td>2.639057</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 04:00:00</th>\n",
       "      <td>train</td>\n",
       "      <td>14.395</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2011-01-01 04:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9.84</td>\n",
       "      <td>...</td>\n",
       "      <td>2011</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     _data   atemp  casual  count             datetime  \\\n",
       "2011-01-01 00:00:00  train  14.395       3     16  2011-01-01 00:00:00   \n",
       "2011-01-01 01:00:00  train  13.635       8     40  2011-01-01 01:00:00   \n",
       "2011-01-01 02:00:00  train  13.635       5     32  2011-01-01 02:00:00   \n",
       "2011-01-01 03:00:00  train  14.395       3     13  2011-01-01 03:00:00   \n",
       "2011-01-01 04:00:00  train  14.395       0      1  2011-01-01 04:00:00   \n",
       "\n",
       "                     holiday  humidity  registered  season  temp    ...      \\\n",
       "2011-01-01 00:00:00        0        81          13       1  9.84    ...       \n",
       "2011-01-01 01:00:00        0        80          32       1  9.02    ...       \n",
       "2011-01-01 02:00:00        0        80          27       1  9.02    ...       \n",
       "2011-01-01 03:00:00        0        75          10       1  9.84    ...       \n",
       "2011-01-01 04:00:00        0        75           1       1  9.84    ...       \n",
       "\n",
       "                     year  hour  dow casual_log  registered_log  count_log  \\\n",
       "2011-01-01 00:00:00  2011     0    5   1.386294        2.639057   2.833213   \n",
       "2011-01-01 01:00:00  2011     1    5   2.197225        3.496508   3.713572   \n",
       "2011-01-01 02:00:00  2011     2    5   1.791759        3.332205   3.496508   \n",
       "2011-01-01 03:00:00  2011     3    5   1.386294        2.397895   2.639057   \n",
       "2011-01-01 04:00:00  2011     4    5   0.000000        0.693147   0.693147   \n",
       "\n",
       "                     peak  perfect  humid  dayofweek  \n",
       "2011-01-01 00:00:00     0        0      0          5  \n",
       "2011-01-01 01:00:00     0        0      0          5  \n",
       "2011-01-01 02:00:00     0        0      0          5  \n",
       "2011-01-01 03:00:00     0        0      0          5  \n",
       "2011-01-01 04:00:00     0        0      0          5  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# RMSLE score function for testing\n",
    "def RMSLE_score(Y_pred, Y_act ):\n",
    "    diff = (np.log(Y_pred + 1) - np.log(Y_act + 1))\n",
    "    mean_error = np.square(diff).mean()\n",
    "    return np.sqrt(mean_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get training data\n",
    "def get_train_data():\n",
    "    train_data = combined_df[combined_df['_data'] == 'train'].copy()\n",
    "    return train_data\n",
    "\n",
    "# get test data\n",
    "def get_test_data():\n",
    "    test_data = combined_df[combined_df['_data'] == 'test'].copy()\n",
    "    return test_data\n",
    "\n",
    "# split train and test data\n",
    "def split_train_test(df, cutoff_day = 15):\n",
    "    train_data = df[df['day'] <= cutoff_day]\n",
    "    test_data = df[df['day'] > cutoff_day]\n",
    "\n",
    "    return train_data, test_data\n",
    "\n",
    "# prepare data for training the model\n",
    "def prepare_data(df, features):\n",
    "    X = df[features].as_matrix()\n",
    "    Y_reg = df['registered_log'].as_matrix()\n",
    "    Y_cas = df['casual_log'].as_matrix()\n",
    "\n",
    "    return X, Y_reg, Y_cas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_kaggle_submission(predictions, file_name):\n",
    "    print \"-\" * 80\n",
    "\n",
    "    # check shape of the test and prediction sets\n",
    "    print \"Generating file for Kaggle Submission File: %s\" % (file_name)\n",
    "    print \"Shape of Kaggle Test Data: \", FINAL_TEST_DF.shape\n",
    "    print \"Shape of Kaggle Test Predictions: \", predictions.shape  \n",
    "\n",
    "    # formatting predictions to integers and removing negative values\n",
    "    predictions = np.rint(predictions)\n",
    "    predictions[ predictions < 0] = 0\n",
    "    print predictions\n",
    "    \n",
    "    print \"Shape of Final Predictions: \", predictions.shape\n",
    "\n",
    "    # create submission file\n",
    "    #sbmt_file_name = [os.getcwd(),'../submissions/',file_name]\n",
    "    sbmt_file_name = file_name\n",
    "    np.savetxt(sbmt_file_name, zip(FINAL_TEST_DF['datetime'], predictions), delimiter=',', fmt=\"%s\", header=','.join(['datetime','count']), comments='')\n",
    "    print \"kaggle submission file generated\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prediction on validation data\n",
    "def predict_validation_data(model, features):\n",
    "    df = get_train_data()\n",
    "\n",
    "    train, test = split_train_test(df)\n",
    "\n",
    "    X_train, Y_train_reg, Y_train_cas = prepare_data(train, features)\n",
    "    X_test, Y_test_reg, Y_test_cas = prepare_data(test, features)\n",
    "\n",
    "    # predict registered users count\n",
    "    model_reg = model.fit(X_train, Y_train_reg)\n",
    "    Y_prd_reg = np.exp(model_reg.predict(X_test)) - 1\n",
    "\n",
    "    # predict casual users count\n",
    "    model_cas = model.fit(X_train, Y_train_cas)\n",
    "    Y_prd_cas = np.exp(model_cas.predict(X_test)) - 1\n",
    "\n",
    "    # combine registered and casual user predictions\n",
    "    Y_prd = np.round(Y_prd_reg + Y_prd_cas)\n",
    "    Y_prd[Y_prd < 0] = 0\n",
    "\n",
    "    # transform predictions back from log\n",
    "    Y_test = np.exp(Y_test_reg) + np.exp(Y_test_cas) - 2\n",
    "\n",
    "    score = RMSLE_score(Y_prd, Y_test)\n",
    "    return (Y_prd, Y_test, score)\n",
    "\n",
    "# predict Kaggle test data & transform output\n",
    "def predict_kaggle_data(model, features):\n",
    "    # get train and test data\n",
    "    train_df = get_train_data()\n",
    "    test_df = get_test_data()\n",
    "\n",
    "    # prepare training data\n",
    "    X_train, Y_train_reg, Y_train_cas = prepare_data(train_df, features)\n",
    "\n",
    "    # prepare test data\n",
    "    X_test = test_df[features].as_matrix()\n",
    "\n",
    "    # predict casual users count\n",
    "    model_cas = model.fit(X_train, Y_train_cas)\n",
    "    Y_prd_cas = np.exp(model_cas.predict(X_test)) - 1\n",
    "    \n",
    "    # predict registered users count\n",
    "    model_reg = model.fit(X_train, Y_train_reg)\n",
    "    Y_prd_reg = np.exp(model_reg.predict(X_test)) - 1\n",
    "\n",
    "    # combine casual & registered predictions together\n",
    "    Y_prd = np.round(Y_prd_reg + Y_prd_cas)\n",
    "    Y_prd[Y_prd < 0] = 0\n",
    "    \n",
    "    return Y_prd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45145158864\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'n_estimators': 1000, \n",
    "    'max_depth': 15, \n",
    "    'random_state': 0, \n",
    "    'min_samples_split' : 5, \n",
    "    'n_jobs': -1}\n",
    "\n",
    "rf_model = RandomForestRegressor(**params)\n",
    "rf_features = [\n",
    "    'weather', 'temp', 'atemp', 'windspeed',\n",
    "    'workingday', 'season', 'holiday', 'humid',\n",
    "    'hour', 'dayofweek', 'peak'\n",
    "    ]\n",
    "\n",
    "(rf_prd, rf_test, rf_score) = predict_validation_data(rf_model, rf_features)\n",
    "print rf_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.319933809759\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'n_estimators': 150, \n",
    "    'max_depth': 5, \n",
    "    'random_state': 0, \n",
    "    'min_samples_leaf' : 10, \n",
    "    'learning_rate': 0.1, \n",
    "    'subsample': 0.7, \n",
    "    'loss': 'ls'}\n",
    "\n",
    "gbm_model = GradientBoostingRegressor(**params)\n",
    "gbm_features = [\n",
    "    'weather', 'temp', 'atemp', 'windspeed',\n",
    "    'workingday', 'season', 'holiday', 'humidity',\n",
    "    'hour', 'dayofweek', 'year', 'perfect'\n",
    "]\n",
    "\n",
    "(gbm_prd, gbm_test, gbm_score) = predict_validation_data(gbm_model, gbm_features)\n",
    "print gbm_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.324200152693\n"
     ]
    }
   ],
   "source": [
    "# combine predictions from both the models\n",
    "# random forest and gradient boost\n",
    "y_prd = np.round(.2 * rf_prd + .8 * gbm_prd)\n",
    "print RMSLE_score(y_prd, rf_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions on Kaggle Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# predict on Kaggle data using random forest\n",
    "rf_prd = predict_kaggle_data(rf_model, rf_features)\n",
    "\n",
    "# predict on Kaggle data using gradient boost\n",
    "gbm_prd = predict_kaggle_data(gbm_model, gbm_features)\n",
    "\n",
    "# combine predictions from both the models\n",
    "# random forest and gradient boost\n",
    "output = np.round(.2 * rf_prd + .8 * gbm_prd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kaggle Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Generating file for Kaggle Submission File: combine_random_forest_grad_boost.csv\n",
      "Shape of Kaggle Test Data:  (6493, 25)\n",
      "Shape of Kaggle Test Predictions:  (6493,)\n",
      "[ 12.   5.   3. ...,  99.  78.  42.]\n",
      "Shape of Final Predictions:  (6493,)\n",
      "kaggle submission file generated\n"
     ]
    }
   ],
   "source": [
    "FINAL_TEST_DF = get_test_data()\n",
    "make_kaggle_submission(output, 'combine_random_forest_grad_boost.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
